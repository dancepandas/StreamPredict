# StreamPredict - åŸºäºLSTMå¤šå¤´æ³¨æ„åŠ›çš„æµé‡é¢„æµ‹ç³»ç»Ÿ

![Python](https://img.shields.io/badge/Python-3.7%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-1.8%2B-orange)
![License](https://img.shields.io/badge/License-MIT-green)

ä¸€ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„æ²³é“æµé‡é¢„æµ‹ç³»ç»Ÿï¼Œé‡‡ç”¨LSTMå’Œå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶å®ç°é«˜ç²¾åº¦çš„æµé‡æ»šåŠ¨é¢„æŠ¥ã€‚

## ğŸŒŸ æ ¸å¿ƒç‰¹æ€§

- **å¤šç‰¹å¾èåˆ**: èåˆå†å²æµé‡ã€é™é›¨ã€è’¸å‘ç­‰å¤šç§æ°´æ–‡è¦ç´ 
- **æ³¨æ„åŠ›æœºåˆ¶**: é‡‡ç”¨å¤šå¤´æ³¨æ„åŠ›æ•è·ä¸åŒç«™ç‚¹å’Œæ—¶é—´çš„å…³é”®ä¿¡æ¯
- **æ»šåŠ¨é¢„æŠ¥**: æ”¯æŒé€æ­¥æ»šåŠ¨é¢„æµ‹ï¼Œå®æ—¶æ›´æ–°é¢„æŠ¥ç»“æœ
- **å®Œæ•´å·¥ç¨‹åŒ–**: ä»æ•°æ®å¤„ç†åˆ°æ¨¡å‹éƒ¨ç½²çš„å®Œæ•´æµç¨‹
- **é«˜ç²¾åº¦é¢„æµ‹**: åŸºäºæ·±åº¦å­¦ä¹ çš„è‡ªå›å½’æ¨¡å‹

## ğŸ“Š æ¨¡å‹æ¶æ„

### StreamModel æ ¸å¿ƒç»„ä»¶

```mermaid
graph TB
    A[å†å²æµé‡åºåˆ—] --> B[LSTM-1]
    C[å†å²é™é›¨åºåˆ—] --> D[Embedding + MultiHead Attention]
    E[å†å²è’¸å‘åºåˆ—] --> F[LSTM-3] 
    G[å½“å‰æ—¶é—´éç›®æ ‡ç‰¹å¾] --> H[LSTM-4]
    
    D --> I[LSTM-2]
    B --> J[ç‰¹å¾èåˆ]
    I --> J
    F --> J
    H --> J
    
    J --> K[MultiHead Attention]
    K --> L[è¾“å‡ºå±‚]
    L --> M[æµé‡é¢„æµ‹å€¼]
```

**æ¨¡å‹ç‰¹ç‚¹**:
- **å››ä¸ªLSTMç¼–ç å™¨**: åˆ†åˆ«å¤„ç†æµé‡ã€é™é›¨ã€è’¸å‘å’Œè¾…åŠ©ç‰¹å¾
- **åŒæ³¨æ„åŠ›æœºåˆ¶**: æ•è·é™é›¨ç«™ç‚¹é—´å…³ç³»å’Œå…¨å±€ç‰¹å¾ä¾èµ–
- **è‡ªå›å½’é¢„æµ‹**: æ”¯æŒå¤šæ­¥æ»šåŠ¨é¢„æŠ¥

**è¾“å…¥æ ¼å¼**:
- å†å²æµé‡åºåˆ—: `[batch_size, 24, 3]` - 24ä¸ªæ—¶é—´æ­¥çš„3ä¸ªæµé‡ç«™ç‚¹
- å†å²é™é›¨åºåˆ—: `[batch_size, 24, 23]` - 24ä¸ªæ—¶é—´æ­¥çš„23ä¸ªé›¨é‡ç«™
- å†å²è’¸å‘åºåˆ—: `[batch_size, 24, 1]` - 24ä¸ªæ—¶é—´æ­¥çš„è’¸å‘æ•°æ®
- å½“å‰ç‰¹å¾: `[batch_size, 26]` - å½“å‰æ—¶é—´æ­¥çš„éç›®æ ‡ç‰¹å¾

## ğŸ—‚ï¸ é¡¹ç›®ç»“æ„

```
StreamPredict/
â”œâ”€â”€ src/                          # æ ¸å¿ƒæºä»£ç æ¨¡å—
â”‚   â”œâ”€â”€ DataProcess.py           # æ•°æ®å¤„ç†å’ŒPyTorchæ•°æ®é›†
â”‚   â”œâ”€â”€ Model.py                 # StreamModelæ·±åº¦å­¦ä¹ æ¨¡å‹
â”‚   â”œâ”€â”€ trainers.py              # æ¨¡å‹è®­ç»ƒå™¨å’Œè¯„ä¼°å™¨
â”‚   â”œâ”€â”€ load_model.py            # æ¨¡å‹åŠ è½½å’Œé¢„æµ‹æ¨¡å—
â”‚   â””â”€â”€ __init__.py              # åŒ…åˆå§‹åŒ–æ–‡ä»¶
â”œâ”€â”€ utils/                        # æ•°æ®å¤„ç†å·¥å…·æ¨¡å—
â”‚   â”œâ”€â”€ check_time_continuous.py # æ—¶é—´åºåˆ—è¿ç»­æ€§æ£€æŸ¥
â”‚   â”œâ”€â”€ merge_all_csv_data.py    # å¤šæºæ•°æ®åˆå¹¶å·¥å…·
â”‚   â”œâ”€â”€ read_features_predict.py # é¢„æµ‹ç‰¹å¾æ•°æ®è¯»å–
â”‚   â””â”€â”€ split_hourly_to_5min.py  # å°æ—¶æ•°æ®è½¬5åˆ†é’Ÿå·¥å…·
â”œâ”€â”€ data/                         # æ•°æ®å­˜å‚¨ç›®å½•
â”‚   â”œâ”€â”€ merged_all_data.csv      # åˆå¹¶åçš„è®­ç»ƒæ•°æ®
â”‚   â”œâ”€â”€ data_p/                  # åŸå§‹å°æ—¶é™é›¨æ•°æ®
â”‚   â”œâ”€â”€ data_p_5min/            # è½¬æ¢åçš„5åˆ†é’Ÿé™é›¨æ•°æ®
â”‚   â”œâ”€â”€ pre_data/               # é¢„æµ‹ç”¨æ•°æ®ç›®å½•
â”‚   â””â”€â”€ [å…¶ä»–æ•°æ®æ–‡ä»¶...]         # æµé‡å’Œè’¸å‘ç­‰åŸå§‹æ•°æ®
â”œâ”€â”€ model_file/                   # æ¨¡å‹æ–‡ä»¶å­˜å‚¨
â”‚   â””â”€â”€ best_model.pth          # è®­ç»ƒå¥½çš„æœ€ä½³æ¨¡å‹
â”œâ”€â”€ standard_scalar/             # æ•°æ®æ ‡å‡†åŒ–å™¨å­˜å‚¨
â”‚   â”œâ”€â”€ standard_stream_scaler.pkl    # æµé‡æ•°æ®æ ‡å‡†åŒ–å™¨
â”‚   â”œâ”€â”€ standard_rainfall_scaler.pkl  # é™é›¨æ•°æ®æ ‡å‡†åŒ–å™¨
â”‚   â”œâ”€â”€ standard_evap_scaler.pkl      # è’¸å‘æ•°æ®æ ‡å‡†åŒ–å™¨
â”‚   â””â”€â”€ standard_current_features_scaler.pkl # ç‰¹å¾æ ‡å‡†åŒ–å™¨
â”œâ”€â”€ fig/                         # å›¾åƒè¾“å‡ºç›®å½•
â”‚   â””â”€â”€ pre_result.png          # é¢„æµ‹ç»“æœå›¾åƒ
â”œâ”€â”€ config.py                    # å…¨å±€é…ç½®æ–‡ä»¶
â”œâ”€â”€ model_train.py               # æ¨¡å‹è®­ç»ƒä¸»è„šæœ¬
â”œâ”€â”€ predict.py                   # æµé‡é¢„æµ‹ä¸»è„šæœ¬
â”œâ”€â”€ requirements.txt             # é¡¹ç›®ä¾èµ–åŒ…åˆ—è¡¨
â””â”€â”€ README.md                    # é¡¹ç›®è¯´æ˜æ–‡æ¡£
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

```bash
python >= 3.7
torch >= 1.8.0
pandas >= 1.2.0
numpy >= 1.19.0
scikit-learn >= 0.24.0
matplotlib >= 3.3.0
joblib >= 1.0.0
tqdm >= 4.60.0
```

### å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### æ•°æ®å‡†å¤‡

1. **åŸå§‹æ•°æ®å¤„ç†**:
```bash
# å°†å°æ—¶é™é›¨æ•°æ®è½¬æ¢ä¸º5åˆ†é’Ÿæ•°æ®
python utils/split_hourly_to_5min.py

# åˆå¹¶æ‰€æœ‰æ•°æ®æº
python utils/merge_all_csv_data.py
```

2. **æ•°æ®æ ¼å¼è¦æ±‚**:
   - æ—¶é—´é—´éš”: 5åˆ†é’Ÿ
   - ç‰¹å¾åˆ—: åŒ…å«æµé‡ã€é™é›¨ã€è’¸å‘ç­‰æ°´æ–‡è¦ç´ 
   - æ—¶é—´æ ¼å¼: `YYYY-MM-DD HH:MM:SS`
   - è®­ç»ƒæ•°æ®: `data/merged_all_data.csv`
   - é¢„æµ‹æ•°æ®: `data/pre_data/features.csv`

### æ¨¡å‹è®­ç»ƒ

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒ
python model_train.py
```

è®­ç»ƒè¿‡ç¨‹ä¼šè‡ªåŠ¨:
- è¯»å– `data/merged_all_data.csv` è®­ç»ƒæ•°æ®
- åˆ›å»ºæ•°æ®æ ‡å‡†åŒ–å™¨å¹¶ä¿å­˜åˆ° `standard_scalar/`
- ä¿å­˜æœ€ä½³æ¨¡å‹åˆ° `model_file/best_model.pth`
- ç”Ÿæˆè®­ç»ƒå†å²å›¾è¡¨åˆ° `fig/` ç›®å½•

### æµé‡é¢„æµ‹

```bash
# æ‰§è¡Œæ»šåŠ¨é¢„æŠ¥
python predict.py
```

é¢„æµ‹è¿‡ç¨‹ä¼š:
- åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ `model_file/best_model.pth`
- è¯»å–é¢„æµ‹æ•°æ® `data/pre_data/features.csv`
- ç”Ÿæˆæ»šåŠ¨é¢„æµ‹ç»“æœå¹¶ä¿å­˜åˆ° `data/pre_data/result.csv`
- æ˜¾ç¤ºé¢„æµ‹ç»“æœå›¾è¡¨

## âš™ï¸ é…ç½®å‚æ•°

### æ¨¡å‹å‚æ•° (config.py)

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `sequence_length` | 24 | å†å²æ•°æ®åºåˆ—é•¿åº¦(æ—¶é—´æ­¥) |
| `num_stream_features` | 3 | æµé‡ç‰¹å¾æ•°é‡ |
| `num_rainfall_features` | 23 | é™é›¨ç«™ç‚¹æ•°é‡ |
| `num_evap_features` | 1 | è’¸å‘ç‰¹å¾æ•°é‡ |
| `hidden_size` | 128 | LSTMéšè—å±‚ç»´åº¦ |
| `num_layers` | 2 | LSTMå±‚æ•° |
| `dropout` | 0.1 | Dropoutæ¯”ä¾‹ |
| `embed_dim` | 128 | æ³¨æ„åŠ›åµŒå…¥ç»´åº¦ |
| `m` | 16 | æ³¨æ„åŠ›å¤´æ•°è®¡ç®—å€æ•° |

### è®­ç»ƒå‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `batch_size` | 32 | æ‰¹æ¬¡å¤§å° |
| `num_epochs` | 100 | æœ€å¤§è®­ç»ƒè½®æ•° |
| `learning_rate` | 0.001 | å­¦ä¹ ç‡ |
| `test_size` | 0.2 | æµ‹è¯•é›†æ¯”ä¾‹ |
| `val_size` | 0.1 | éªŒè¯é›†æ¯”ä¾‹ |
| `random_state` | 42 | éšæœºç§å­ |

### æ–‡ä»¶è·¯å¾„é…ç½®

| é…ç½®é¡¹ | è·¯å¾„ | è¯´æ˜ |
|-------|------|------|
| `data_file` | `data/merged_all_data.csv` | è®­ç»ƒæ•°æ®æ–‡ä»¶ |
| `data_predict_file` | `data/pre_data` | é¢„æµ‹æ•°æ®ç›®å½• |
| `standard_scalar_file` | `standard_scalar` | æ ‡å‡†åŒ–å™¨å­˜å‚¨ç›®å½• |
| `model_save_file` | `model_file/best_model.pth` | æ¨¡å‹ä¿å­˜è·¯å¾„ |
| `fig_save_file` | `fig` | å›¾åƒä¿å­˜ç›®å½• |

## ğŸ“ˆ è®­ç»ƒç›‘æ§

è®­ç»ƒè¿‡ç¨‹åŒ…å«ä»¥ä¸‹ç›‘æ§æŒ‡æ ‡:

- **æŸå¤±å‡½æ•°**: RMSE (å‡æ–¹æ ¹è¯¯å·®)
- **æ—©åœæœºåˆ¶**: é˜²æ­¢è¿‡æ‹Ÿåˆ (patience=50)
- **å­¦ä¹ ç‡è°ƒåº¦**: ReduceLROnPlateauè‡ªé€‚åº”è°ƒæ•´
- **æ¢¯åº¦è£å‰ª**: é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ (max_norm=1.0)
- **æƒé‡è¡°å‡**: L2æ­£åˆ™åŒ– (weight_decay=1e-5)

è®­ç»ƒå®Œæˆåè‡ªåŠ¨ç”Ÿæˆ:
- `fig/training_history.png`: è®­ç»ƒå’ŒéªŒè¯æŸå¤±æ›²çº¿
- `fig/predictions.png`: é¢„æµ‹ç»“æœå¯¹æ¯”å›¾
- `model_file/best_model.pth`: æœ€ä½³æ¨¡å‹æƒé‡æ–‡ä»¶

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | è¯´æ˜ | ç”¨é€” |
|------|------|------|
| **MSE** | å‡æ–¹è¯¯å·® | åŸºç¡€è¯¯å·®åº¦é‡ |
| **RMSE** | å‡æ–¹æ ¹è¯¯å·® | ä¸»è¦ä¼˜åŒ–ç›®æ ‡ |
| **MAE** | å¹³å‡ç»å¯¹è¯¯å·® | é²æ£’æ€§è¯„ä¼° |
| **RÂ²** | å†³å®šç³»æ•° | æ¨¡å‹è§£é‡Šèƒ½åŠ› |
| **MAPE** | å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·® | ç›¸å¯¹è¯¯å·®è¯„ä¼° |

## ğŸ”„ æ»šåŠ¨é¢„æŠ¥

ç³»ç»Ÿæ”¯æŒå®æ—¶æ»šåŠ¨é¢„æŠ¥:

1. **æ•°æ®è¾“å…¥**: è¯»å– `data/pre_data/features.csv`
2. **åºåˆ—æ„å»º**: æå–æœ€è¿‘24ä¸ªæ—¶é—´æ­¥çš„å†å²æ•°æ®
3. **æ¨¡å‹é¢„æµ‹**: ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹é¢„æµ‹ä¸‹ä¸€æ—¶é—´æ­¥æµé‡
4. **ç»“æœæ›´æ–°**: å°†é¢„æµ‹å€¼ä½œä¸ºä¸‹ä¸€è½®çš„è¾“å…¥ç‰¹å¾
5. **è´¨é‡æ£€æŸ¥**: è‡ªåŠ¨éªŒè¯æ—¶é—´è¿ç»­æ€§å’Œæ•°æ®å®Œæ•´æ€§
6. **ç»“æœä¿å­˜**: è¾“å‡ºåˆ° `data/pre_data/result.csv`

### é¢„æµ‹æµç¨‹ç›‘æ§
- å®æ—¶æ˜¾ç¤ºé¢„æµ‹è¿›åº¦
- è‡ªåŠ¨æ£€æµ‹æ•°æ®å¼‚å¸¸å¹¶å¤„ç†
- æ”¯æŒä¸­æ–­æ¢å¤å’Œé”™è¯¯å¤„ç†

## ğŸ’¡ æŠ€æœ¯äº®ç‚¹

### 1. å¤šå°ºåº¦ç‰¹å¾èåˆ
- **æ—¶é—´ç»´åº¦**: 24æ­¥å†å²åºåˆ— (2å°æ—¶å†å²ä¿¡æ¯)
- **ç©ºé—´ç»´åº¦**: 23ä¸ªé™é›¨ç«™ç‚¹çš„ç©ºé—´åˆ†å¸ƒ
- **è¦ç´ ç»´åº¦**: æµé‡ã€é™é›¨ã€è’¸å‘ç­‰æ°´æ–‡è¦ç´ 
- **ç«™ç‚¹ç»´åº¦**: å®˜å…ã€æ–‹å ‚ã€é›ç¿…3ä¸ªæµé‡ç›‘æµ‹ç«™

### 2. åŒæ³¨æ„åŠ›æœºåˆ¶
- **é™é›¨æ³¨æ„åŠ›**: è¯†åˆ«å…³é”®é™é›¨ç«™ç‚¹å¯¹ç›®æ ‡æµé‡çš„å½±å“æƒé‡
- **å…¨å±€æ³¨æ„åŠ›**: æ•è·æ‰€æœ‰æ—¶ç©ºç‰¹å¾é—´çš„å¤æ‚éçº¿æ€§å…³ç³»

### 3. å·¥ç¨‹åŒ–è®¾è®¡
- **æ•°æ®æµæ°´çº¿**: è‡ªåŠ¨åŒ–æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹
- **æ¨¡å‹ç®¡ç†**: å®Œæ•´çš„è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•æµç¨‹
- **ç»“æœå¯è§†åŒ–**: è‡ªåŠ¨ç”Ÿæˆè®­ç»ƒæ›²çº¿å’Œé¢„æµ‹å¯¹æ¯”å›¾
- **å¼‚å¸¸å¤„ç†**: æ•°æ®è´¨é‡æ£€æŸ¥å’Œé”™è¯¯æ¢å¤æœºåˆ¶

## ğŸ› ï¸ æ•°æ®å¤„ç†å·¥å…·

### æ—¶é—´åºåˆ—å¤„ç†
```bash
# å°æ—¶æ•°æ®è½¬5åˆ†é’Ÿæ•°æ®
python utils/split_hourly_to_5min.py
```
- è¾“å…¥: `data/data_p/` å°æ—¶é™é›¨æ•°æ®
- è¾“å‡º: `data/data_p_5min/` 5åˆ†é’Ÿé™é›¨æ•°æ®
- æ–¹æ³•: çº¿æ€§æ’å€¼å¤„ç†æ—¶é—´é—´éš”â‰¤2å°æ—¶çš„æ•°æ®

### æ•°æ®åˆå¹¶
```bash
# åˆå¹¶å¤šæºæ•°æ®
python utils/merge_all_csv_data.py
```
- åˆå¹¶: æµé‡ã€é™é›¨ã€è’¸å‘ç­‰å¤šç§æ•°æ®æº
- è¾“å‡º: `data/merged_all_data.csv` ç»Ÿä¸€è®­ç»ƒæ•°æ®
- ç­–ç•¥: å†…è¿æ¥ä¿è¯æ—¶é—´å¯¹é½

### æ•°æ®è´¨é‡æ£€æŸ¥
```python
from utils.check_time_continuous import check_time_continuous

# æ£€æŸ¥æ—¶é—´åºåˆ—è¿ç»­æ€§
is_continuous = check_time_continuous('data.csv')
```

### é¢„æµ‹ç‰¹å¾è¯»å–
```python
from utils.read_features_predict import creat_temp_data

# åˆ›å»ºé¢„æµ‹ç”¨ä¸´æ—¶æ•°æ®
creat_temp_data(features_data_file, lines, sequence_length, predict_result, temp_file)
```

## ğŸ“ ä½¿ç”¨æ¡ˆä¾‹

### å®Œæ•´è®­ç»ƒæµç¨‹
```python
from src.trainers import StreamModelTrainer
import config

# 1. åˆ›å»ºè®­ç»ƒå™¨
trainer = StreamModelTrainer(
    data_file=config.data_file,
    standard_scalar_file=config.standard_scalar_file
)

# 2. å‡†å¤‡æ•°æ®
train_loader, val_loader, test_loader = trainer.prepare_data(
    batch_size=config.batch_size
)

# 3. è®­ç»ƒæ¨¡å‹
history = trainer.train(
    train_loader=train_loader,
    val_loader=val_loader,
    num_epochs=config.num_epochs,
    learning_rate=config.learning_rate
)

# 4. è¯„ä¼°æ¨¡å‹
metrics = trainer.evaluate(test_loader)
print(f"RMSE: {metrics['RMSE']:.4f}")
print(f"RÂ²: {metrics['R2']:.4f}")

# 5. å¯è§†åŒ–ç»“æœ
trainer.plot_training_history()
trainer.plot_predictions(metrics)
```

### æ‰§è¡Œé¢„æµ‹
```python
from src.load_model import StreamPredict

# åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
predictor = StreamPredict(
    model_path=config.model_save_file,
    data_file=config.data_predict_file + '/features.csv',
    standard_scalar=config.standard_scalar_file
)

# åŠ è½½æ¨¡å‹å¹¶æ‰§è¡Œé¢„æµ‹
predictor.load_model()
predictions= predictor.predict()

# å¯è§†åŒ–é¢„æµ‹ç»“æœ
predictor.plot_predictions(predictions)
```

### è‡ªå®šä¹‰é…ç½®
```python
# ä¿®æ”¹æ¨¡å‹å‚æ•°
custom_config = {
    'sequence_length': 48,  # ä½¿ç”¨4å°æ—¶å†å²æ•°æ®
    'hidden_size': 256,     # å¢å¤§æ¨¡å‹å®¹é‡
    'num_layers': 3,        # æ·»åŠ æ›´å¤šLSTMå±‚
    'dropout': 0.2          # å¢å¼ºæ­£åˆ™åŒ–
}

trainer = StreamModelTrainer(
    data_file=config.data_file,
    standard_scalar_file=config.standard_scalar_file,
    model_config=custom_config
)
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æ•°æ®æ—¶é—´ä¸è¿ç»­**
   - ç—‡çŠ¶: è®­ç»ƒæ•°æ®é‡å°‘äºé¢„æœŸ
   - æ£€æŸ¥: `utils.check_time_continuous()`
   - è§£å†³: è¡¥å……ç¼ºå¤±æ—¶é—´ç‚¹æˆ–è°ƒæ•´æ—¶é—´èŒƒå›´

2. **å†…å­˜ä¸è¶³**
   - ç—‡çŠ¶: CUDA out of memory é”™è¯¯
   - è§£å†³: å‡å° `config.batch_size` (å¦‚æ”¹ä¸º16æˆ–8)
   - å¤‡é€‰: å‡å°‘ `config.sequence_length`

3. **è®­ç»ƒä¸æ”¶æ•›**
   - ç—‡çŠ¶: éªŒè¯æŸå¤±ä¸ä¸‹é™
   - è§£å†³æ–¹æ¡ˆ:
     - æ£€æŸ¥æ•°æ®æ ‡å‡†åŒ–æ˜¯å¦æ­£ç¡®
     - è°ƒæ•´å­¦ä¹ ç‡ `config.learning_rate`
     - å¢åŠ è®­ç»ƒè½®æ•° `config.num_epochs`
     - è°ƒæ•´æ¨¡å‹å¤æ‚åº¦

4. **é¢„æµ‹ç»“æœå¼‚å¸¸**
   - ç—‡çŠ¶: é¢„æµ‹å€¼å…¨ä¸º0æˆ–å¼‚å¸¸å¤§
   - æ£€æŸ¥: æ¨¡å‹æ–‡ä»¶å’Œæ ‡å‡†åŒ–å™¨æ˜¯å¦åŒ¹é…
   - è§£å†³: é‡æ–°è®­ç»ƒæˆ–æ£€æŸ¥æ•°æ®è´¨é‡

5. **æ–‡ä»¶è·¯å¾„é”™è¯¯**
   - ç—‡çŠ¶: FileNotFoundError
   - æ£€æŸ¥: `config.py` ä¸­çš„è·¯å¾„é…ç½®
   - è§£å†³: ç¡®ä¿æ‰€æœ‰å¿…è¦ç›®å½•å’Œæ–‡ä»¶å­˜åœ¨

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **GPUåŠ é€Ÿ**: ç¡®ä¿å®‰è£…CUDAç‰ˆæœ¬çš„PyTorch
2. **æ•°æ®å¹¶è¡Œ**: å¢åŠ DataLoaderçš„num_workers
3. **æ¨¡å‹è°ƒä¼˜**: æ ¹æ®æ•°æ®ç‰¹ç‚¹è°ƒæ•´ç½‘ç»œæ¶æ„
4. **å†…å­˜ä¼˜åŒ–**: ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯å¤„ç†å¤§æ‰¹æ¬¡

## ğŸ“„ è®¸å¯è¯

MIT License - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Request æ¥æ”¹è¿›é¡¹ç›®ï¼

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»:
- æäº¤ GitHub Issue
- å‘é€é‚®ä»¶è‡³Chs9710@163.com
